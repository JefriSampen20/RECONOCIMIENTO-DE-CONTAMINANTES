# üß™ Proyecto de Detecci√≥n de Contaminantes en Frutas
Somos estudiantes de la Universidad Nacional de Piura, de la Escuela Profesional de Ingenier√≠a Electr√≥nica y Telecomunicaciones. En este proyecto desarrollamos un sistema de visi√≥n por computadora enfocado en la detecci√≥n de contaminantes, utilizando t√©cnicas de autoetiquetado, procesamiento de im√°genes, y entrenamiento de modelos de detecci√≥n basados en inteligencia artificial.

# Descripci√≥n general del proyecto

El objetivo principal fue detectar y clasificar tres tipos diferentes de contaminantes presentes en distintos entornos. Para ello, trabajamos con un total de 300 im√°genes, distribuidas en tres etiquetas principales (100 im√°genes por clase), las cuales fueron procesadas y anotadas en el formato YOLOv8.

# Autoetiquetado con Grounding DINO

Con el fin de reducir el tiempo invertido en la anotaci√≥n manual, implementamos un sistema de autoetiquetado semiautom√°tico utilizando el modelo Grounding DINO. Este modelo permite generar cajas delimitadoras (bounding boxes) precisas a partir de descripciones en lenguaje natural.

Grounding DINO combina un componente visual y uno ling√º√≠stico en una sola arquitectura. Est√° compuesto por:

- Una red vision-language multimodal, que utiliza un Vision Transformer (ViT) para la parte visual y un Transformer para la parte textual.

- Un m√©todo de refinamiento iterativo, que mejora progresivamente las predicciones del modelo, logrando mayor precisi√≥n y coherencia en los resultados.

Gracias a este enfoque, pudimos:

- Generar autom√°ticamente las bounding boxes para cada contaminante en las im√°genes.

- Asignar etiquetas correspondientes seg√∫n los tipos de contaminantes definidos previamente.

- Acelerar el proceso de etiquetado, manteniendo la calidad de los datos de entrenamiento.

# Procesamiento de Im√°genes

Antes del entrenamiento del modelo, cada imagen fue sometida a un preprocesamiento, con el objetivo de normalizar su formato y asegurar consistencia en el dataset. Las operaciones aplicadas fueron:

- Correcci√≥n autom√°tica de orientaci√≥n de los p√≠xeles.

- Redimensionamiento de todas las im√°genes a una resoluci√≥n fija de 640 √ó 640 p√≠xeles, ajustando las proporciones mediante estiramiento.

# Aumento de Datos (Data Augmentation)

Para aumentar la cantidad y variedad del conjunto de datos, se aplicaron t√©cnicas de aumento autom√°tico, generando tres versiones adicionales por cada imagen original. Estas t√©cnicas incluyeron:

- Rotaciones aleatorias de 0¬∞, 90¬∞ (sentido horario y antihorario).

- Rotaciones adicionales entre ‚Äì15¬∞ y +15¬∞.

- Aplicaci√≥n de desenfoque gaussiano aleatorio, entre 0 y 1 p√≠xeles.

Este conjunto enriquecido de datos permiti√≥ entrenar modelos m√°s robustos, capaces de reconocer los contaminantes en distintas condiciones de luz, orientaci√≥n y enfoque.

# Anotaciones

Todas las anotaciones generadas fueron estructuradas en el formato YOLOv8, lo que facilit√≥ el entrenamiento del modelo utilizando herramientas modernas y eficientes de detecci√≥n de objetos.

# Librer√≠as utilizadas

Durante el desarrollo del proyecto, se emplearon las siguientes librer√≠as y herramientas principales en el entorno Python:

- torch ‚Äì para manejo de modelos basados en PyTorch.

- opencv-python ‚Äì para lectura, visualizaci√≥n y manipulaci√≥n de im√°genes.

- numpy ‚Äì para operaciones matriciales y procesamiento de datos.

- matplotlib ‚Äì para visualizaci√≥n de resultados y an√°lisis gr√°fico.

- PIL (Pillow) ‚Äì para operaciones de carga y transformaci√≥n de im√°genes.

- transformers ‚Äì para usar modelos de lenguaje preentrenados, √∫tiles en la etapa ling√º√≠stica de Grounding DINO.

- GroundingDINO ‚Äì librer√≠a base del modelo vision-language utilizado para el autoetiquetado.

- ultralytics ‚Äì para la implementaci√≥n y entrenamiento con el modelo YOLOv8.

- pycocotools ‚Äì para la conversi√≥n y manipulaci√≥n de formatos de anotaci√≥n (COCO, si es necesario).

- tqdm ‚Äì para visualizar barras de progreso durante procesos largos.

# Procedimientos de instalaci√≥n y configuraci√≥n

A continuaci√≥n, se describen los pasos b√°sicos para instalar y configurar el entorno del proyecto:

## 1. Crear entorno virtual (opcional pero recomendado)

    python -m venv venv
    source venv/bin/activate   # En Linux/macOS
    venv\Scripts\activate.bat  # En Windows

## 2. Clonar los repositorios necesarios

git clone https://github.com/IDEA-Research/GroundingDINO.git
cd GroundingDINO

## 3. Instalar dependencias principales

    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    pip install opencv-python numpy matplotlib pillow transformers
    pip install -e .  # para instalar GroundingDINO como paquete local

## 4. Instalar Ultralytics (YOLOv8)

    pip install ultralytics

## 5. Instalar otras utilidades

    pip install pycocotools tqdm

Nota: Aseg√∫rate de tener Python 3.8 o superior y una versi√≥n de CUDA compatible si planeas usar GPU. Puedes verificar la compatibilidad en la p√°gina oficial de PyTorch.

# Autores

- AREVALO MENDOZA ALESSANDRO MIGUEL
- GONZALES ALVARADO SEBASTIAN ANTONY
- SAMPEN CHANCAFE JEFFERSON ARMANDO

# Licencia

Este proyecto est√° bajo la licencia MIT. Puedes usar, modificar y distribuir este c√≥digo con fines educativos y de investigaci√≥n, siempre que se otorgue el debido cr√©dito.

# Cr√©ditos

* Universidad Nacional de Piura

* Escuela Profesional de Ingenier√≠a Electr√≥nica y Telecomunicaciones

* IDEA Research (GroundingDINO)

Ultralytics (YOLOv8)
